{"extracted_information": "网页内容提供了pyannote-audio项目的GitHub README信息，涵盖了项目的简介、安装方法、基本使用示例、依赖项、性能基准、文档链接、社区贡献以及开发相关信息。它是一个基于PyTorch的开源工具包，用于说话人区分（speaker diarization）。", "specifications": {"开发语言": "Python", "机器学习框架": "PyTorch", "支持Python版本": "不再支持 Python 3.8（根据提交记录）"}, "pricing": {}, "features": ["说话人区分（speaker diarization）", "语音活动检测（speech activity detection）", "说话人变化检测（speaker change detection）", "重叠语音检测（overlapped speech detection）", "说话人嵌入（speaker embedding）", "基于 Hugging Face 模型中心的预训练模型和管道", "支持多 GPU 训练（基于 pytorch-lightning）"], "statistics": {"GitHub Star数量": "7.7k", "GitHub Fork数量": "889", "基准测试Diarization Error Rate (DER)": {"AISHELL-4": {"v2.1": "14.1%", "v3.1": "12.2%", "pyannoteAI": "11.9%"}, "AliMeeting (channel 1)": {"v2.1": "27.4%", "v3.1": "24.4%", "pyannoteAI": "22.5%"}, "AMI (IHM)": {"v2.1": "18.9%", "v3.1": "18.8%", "pyannoteAI": "16.6%"}, "AMI (SDM)": {"v2.1": "27.1%", "v3.1": "22.4%", "pyannoteAI": "20.9%"}, "AVA-AVD": {"v2.1": "66.3%", "v3.1": "50.0%", "pyannoteAI": "39.8%"}, "CALLHOME (part 2)": {"v2.1": "31.6%", "v3.1": "28.4%", "pyannoteAI": "22.2%"}, "DIHARD 3 (full)": {"v2.1": "26.9%", "v3.1": "21.7%", "pyannoteAI": "17.2%"}, "Earnings21": {"v2.1": "17.0%", "v3.1": "9.4%", "pyannoteAI": "9.0%"}, "Ego4D (dev.)": {"v2.1": "61.5%", "v3.1": "51.2%", "pyannoteAI": "43.8%"}, "MSDWild": {"v2.1": "32.8%", "v3.1": "25.3%", "pyannoteAI": "19.8%"}, "RAMC": {"v2.1": "22.5%", "v3.1": "22.2%", "pyannoteAI": "18.4%"}, "REPERE (phase2)": {"v2.1": "8.2%", "v3.1": "7.8%", "pyannoteAI": "7.6%"}, "VoxConverse (v0.3)": {"v2.1": "11.2%", "v3.1": "11.3%", "pyannoteAI": "9.4%"}}}, "temporal_info": {"最新版本": "Version 3.3.1 (Jun 23, 2024)"}, "geographical_data": {}, "references": ["项目官网: http://pyannote.github.io", "Hugging Face pyannote 模型: https://huggingface.co/pyannote", " Hugging Face 模型 pyannote/segmentation-3.0: https://hf.co/pyannote/segmentation-3.0", " Hugging Face 模型 pyannote/speaker-diarization-3.1: https://hf.co/pyannote/speaker-diarization-3.1", "创建 Hugging Face 访问令牌: https://hf.co/settings/tokens", "文档: https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax (链接指向搜索语法，非项目文档主页)", "详细文档链接 (Readme中提及): CHANGELOG.md, FAQ.md, 教程ipynb文件等", "PyTorch 框架: pytorch.org", "pytorch-lightning 框架: pytorchlightning.ai/", "引用: Plaquet23 (INTERSPEECH 2023)", "引用: Bredin23 (INTERSPEECH 2023)", "生产环境替代方案: pyannoteAI (https://www.pyannote.ai)"], "installation": {"方法": "pip install pyannote.audio"}, "dependencies": {"主要框架": "PyTorch", "其他依赖": "通过 pip 安装，详细列表在 requirements.txt 中（内容未直接提供）", "运行时依赖": ["访问 Hugging Face 模型 (如 pyannote/segmentation-3.0, pyannote/speaker-diarization-3.1)", "接受 Hugging Face 模型用户使用条件", "Hugging Face 访问令牌"]}, "basic_usage": {"示例代码": ["from pyannote.audio import Pipeline", "import torch", "", "# 1. 加载预训练管道（需要 Hugging Face 访问令牌）", "pipeline = Pipeline.from_pretrained(", "    \"pyannote/speaker-diarization-3.1\",", "    use_auth_token=\"HUGGINGFACE_ACCESS_TOKEN_GOES_HERE\")", "", "# 2. 将管道发送到 GPU (如果可用)", "pipeline.to(torch.device(\"cuda\"))", "", "# 3. 应用管道到音频文件", "diarization = pipeline(\"audio.wav\")", "", "# 4. 打印结果", "for turn, _, speaker in diarization.itertracks(yield_label=True):", "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"], "输出示例": ["start=0.2s stop=1.5s speaker_0", "start=1.8s stop=3.9s speaker_1", "start=4.2s stop=5.7s speaker_0", "..."]}, "important_notes": ["需要接受 Hugging Face 上预训练模型 (pyannote/segmentation-3.0, pyannote/speaker-diarization-3.1) 的用户使用条件。", "需要创建并使用 Hugging Face 访问令牌来加载预训练模型。", "项目建议在生产环境考虑使用 pyannoteAI (商业服务)，可能提供更好或更快的选项。", "支持使用 GPU 进行加速处理。", "已移除对 Python 3.8 的支持（根据提交记录）。", "提供详细文档、常见问题解答 (FAQ) 和教程，建议查阅以获取更多信息。"]}